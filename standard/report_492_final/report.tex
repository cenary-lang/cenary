\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\graphicspath{ {images/} }
\usepackage{listings}
\usepackage{color}
\usepackage{textcomp}

\title{Cmpe492 Final Progress Report}
\author{
  Yiğit Özkavcı \\
  \texttt{2013400111} \\
  \texttt{yigit.ozkavci@boun.edu.tr}
}
\date{June 2018}

\begin{document}

% Set lstlisting options
\definecolor{listinggray}{gray}{0.9}
\definecolor{lbcolor}{rgb}{0.9,0.9,0.9}
\lstset{
	backgroundcolor=\color{lbcolor},
	tabsize=4,
	rulecolor=,
	language=Haskell,
        basicstyle=\scriptsize,
        upquote=true,
        aboveskip={1.5\baselineskip},
        columns=fixed,
        showstringspaces=false,
        extendedchars=true,
        breaklines=true,
        prebreak = \raisebox{0ex}[0ex][0ex]{\ensuremath{\hookleftarrow}},
        frame=single,
        showtabs=false,
        showspaces=false,
        showstringspaces=false,
        identifierstyle=\ttfamily,
        keywordstyle=\color[rgb]{0,0,1},
        commentstyle=\color[rgb]{0.133,0.545,0.133},
        stringstyle=\color[rgb]{0.627,0.126,0.941},
}

\maketitle

\tableofcontents

\newpage

\section{Introduction}
\par 
\par This is the CMPE492 final progress report for project Cenary, a programming language for writing smart contracts on Ethereum Virtual Machine (will be referred as EVM from now on).
\par This report represents the conclusion of the 1-year progress of Cenary.

\par This term's work focused on runtime representation of various newly-introduced data structures such as dynamic arrays and hashmaps. Aside from dynamic data structures, we also improved our development workflow, introduced several test scenarios.

\section{Dynamic Memory}
When it comes to representing dynamic data structures, EVM actually is not so different than other virtual machines. We are still able to split memory in stack and heap parts, on which stack represents static allocations and heap represents dynamic ones.
\par The only differing part of EVM in this manner is that EVM has two separate ways of storing things in memory: MEMORY and STORAGE. MEMORY represents temporary storage, which means that whatever we store in MEMORY, we will have them wiped out after our function call terminates. This corresponds to local variables in programming; whereas STORAGE represents persistent storage, whatever is stored here, persist through the lifetime of the contract on blockchain.
\par There are more details on how MEMORY and STORAGE works under the hood, and we dive into their details in the following subsections.
\subsection{MEMORY}
\label{memory}
MEMORY is the temporary memory for ethereum smart contracts. It's cheap to use incrementally, but there is an important detail in using memory: when a contract is deployed, the farthest location we allocate is considered the memory limit we allocate, hence we need to make use of memory very carefully. So if we were to only allocate memory location 0x2460, contract is said to allocate 0x2460 x 0x20 bytes of memory, so it's crucial that we make use of every part until the maximum point of memory allocation.
\subsection{STORAGE}
Storage is the persistent memory for ethereum smart contracts. We represent storage varibables as global variables in Cenary. Storage is generally very expensive to use, but for it's also a much better way to store hashmaps because of how MEMORY works in EVM. (see \ref{memory}). We will discuss how we store hashmaps and compute hashing function later in section \ref{hashmaps}

\section{Dynamic Data Structures}
\subsection{Runtime Representation}
\label{runtime-rep}
In order to represent dynamic data structures, we first needed to change our representation of operands, which correspond to mostly right-hand side in the context of Cenary. Until now, we evaluated our operands, stored them then got their addresses in compile-time. But as you might imaginge, it's impossible to know address of a runtime variable at compile time. Because of this limitation, we started no longer storing operand addresses, but instead, have their values in our stack. So for a statement like this: $int\ a = 5;$, we first evaluate 5, which is $EInt\ 5$, we push $0x05$ to stack then return; after having evaluated the operand, we store the first element of stack (which is 5 in this case) in the address of $a$. This part is crucial: we always store variable addresses in our lookup table, but for the operands, we may or may not know the address, so they are represented in stack instead.
\subsection{Arrays}
\label{arrays}
Representing arrays in heap space required planning since we needed a well-defined structure for storage. We decided on the following pattern:

\begin{center}
  \begin{tabular}{ | l | l | l | l | }
    \hline
    length & element 1 & element 2 & \ldots \\
    \hline
  \end{tabular}
\end{center}
But where do we put this? We know that array identifier's address should be static, so when user types $int[]\ arr$, we need to determine a stack address for this variable, and it should not change. We concluded that stack address should point to a ``variable heap address''. This means that we know how to access array contents, but we don't know the actual destination of it. \\
\\
\begin{tabular}{ | c | c   c   c | c | c | c | }
  \hline
  \textbf{Values} & arr-addr & \textgreater \ldots \textless & length & element 1 & element 2 & \ldots \\
  \hline
  \textbf{Addresses} & stack-addr & \textgreater \ldots \textless & arr-addr & arr-addr + 0x20 & arr-addr + 0x40 & \ldots \\
  \hline
  \textbf{Spaces} & Stack Space & \textgreater \ldots \textless & \multicolumn{4}{c|}{ Heap Space } \\
  \hline
\end{tabular} \\

\par Above figure represents how we store an array in heap space. The value in stack address acts like a pointer to the address where we store array in heap. When we go to that address, we have the array size, and then we can safely traverse the whole array.
\newpage
\subsubsection{Resizing Arrays}
\label{resizing}
\par Resizing arrays involved more EVM assembly code than we expected, and it turns out that it was because it involed both reading and storing chunk of arrays. \\
Task of resizing arrays branches into 2 distinct parts: when we want to shrink it, or expand it. Shrinking is easy: we just set the size of the array to a smaller value; this lets us treat this array with the new length from now on. \\
\par The more difficult part is the expanding part while resizing arrays, because we need to find a larger place for the array since we don't have the guarantee that array will reside in the edge all the time, obviously. So we first started the procedure of allocating an array with the same length, and inside a for loop (which are just jumps in EVM assembly) we carried elements one by one. Of course, we do this in runtime with a loop, not by pasting more and more instructions since it would result in a larger bytecode.
\par The new space in the array is only a bunch of zeros (0x00). We don't throw any error in case user wants to access these places, even though we might throw errors in future. For more on exceptions and logging, see \ref{runtime-exceptions} and \ref{logging}

\subsection{Hashmaps}
\label{hashmaps}
\par There are not enough information on how to store hashmaps on EVM, but we made use of this great article \cite{hash-table-poisoning} in order to accomplish this task. It turns out that EVM actually is quite supportive when it comes to store key-value data, but with one small detail: we can do it only in STORAGE. We will come to the reason in this section, but after we discussed computing the hash function.

\par Computing the hash function is not a very complicated task since we have the necessary tools: a key to differentiate each hashmap and their keys, and a hashing function. We will use keccak256 hashing, which is accomplished in runtime via $SHA3$ instruction of EVM. We absolutely need to do this in runtime because we may or may not know the key to the hashing function. But how do we find the suitable key?
\par We have two components as the key to the hashing function: key of the mapping identifier (for $myMap["foo"]$, it's $"foo"$), and something to uniquely identify our maps: ordering for the identifiers (ie. $myMap$). For each mapping identifier, we have a integer as ordering that starts from zero and increments by one. So if we have hashmaps $map1$, $map2$, $map3$, ordering of $map2$ is $1$. Then we concatenate these two values, and we have our key to the hashing function. Below, we present some examples and their hashing results:

\begin{center}
  \begin{tabular} { | c | c | c | c | }
    \hline
    Variable & Identifier & Key & Hashing Function \\
    \hline
    $myMap["name"]$ & myMap & name & SHA3(order(myMap) ++ name) \\
    \hline
    $secondMap["key2"]$ & secondMap & key2 & SHA3(order(secondMap) ++ key2) \\
    \hline
  \end{tabular}
\end{center}
\newpage
\par Now that we have our hashing function, we can start storing and reading hashmap values. We use result of the hashing function as the address to our values, but these adresses are weird and random-looking values, and if we are to use them as addresses, we are going to have a very discrete scheme of values on our memory. As we discussed how MEMORY and STORAGE structured, and with MEMORY we were assumed to have allocated every cell until our latest allocation, allocating the addressed that are resulted from hashing functions are obviously infeasible since we would end up with allocating massive amounts of memory for no reason.
\par This is actually the very limitation Solidity still has: noone can use hashmaps in local scope with Solidity, since local variables correspond to MEMORY, in other words, the temporary storage in solidity. Hence, we also allow users to declare (and define) their hashmaps only in global scope.
\par Not being able to allocate hashmaps in local scope might be a limitation that we can overcome in the future, but it surely is going to alter the way we store our hashmap values.
\section{New Language Features}
\label{new-language-features}
\subsection{Runtime Exceptions (Halting)}
With the coming of runtime data structures, the concept of runtime exceptions arose. If someone tries to reach to a non-existing index of an array, we can currently detect it since we keep the length information in heap, and we have the indexing operand at hand. With $LT, GT and EQ$ instructions, we can compare the index with the existing length and determine whether someone tries to access an out of bound index of an array. In this case, we print a log message (event in Solidity terminology) and halt the execution, hence ending the transaction.

\par If we don't control this scenario, user was going to receive the value 0x00 without noticing s/he actually made a mistake; this is a case we want to avoid since in the philosophy of Cenary, we have safety in mind.

\par In the case of hashmaps and accessing a non-existing key, we don't check it since smart contract developers are used to Solidity conventions, which keeps saying ``when a hashmap is created, every value is filled with zeros'', hence no access violate the hashmap lookup. This state might change in future.
\label{runtime-exceptions}
\newpage
\subsection{Logging}
\label{logging}
\par EVM provides several instructions for working with logging, and they are surprisingly rich in terms of categorisation. We can optionally include topics in our logs, and we can put anything we want as topics (limitation is 0x20/32 bytes). For the contents of logs, we don't put the contents of logs to stack as an input to LOG instructions, but instead, we put the address limits of the content. So if we want to log some content, we need to have it in memory, and specify its beginning and ending address as an input to instruction. This is actually a very clever way of representing can-be-large content since we can use up to 32 bytes as address.

\par With out javascript client which makes our deployment easy for us, we currently collect logs from every running Cenary transaction and display it. This is a \textbf{very} helpful way of debugging programs, since we now have a way of seeing actual runtime values for any Cenary programs, which would have been impossible without the logs since runtime is theoretically in any computer.

\section{Compiler Features}
\subsection{Testing}
In the Spring 2018 term, we greatly improved our testing suite. We currently have 13 testing scenarios and for each one we start a test network, deploy our contract and run the transaction then collect and assert the result. It's currently very easy to write tests on cenary: one just needs to modify $test/assertions$ file and it's good to go. The file currently has the following structure:
\lstinputlisting[language=bash]{../../test/assertions}

\newpage
\subsection{Showing AST}
Cenary compiler can also perform other tasks than actually compiling and running tests. It can show only the Abstract Syntax Tree of the cenary program given as input. This is a powerful feature that we have for free when we modulate the compiling pipeline good enough. As we described in older reports, we have the following pipeline: $lexing\ -> parsing\ -> code\ generation$.
\subsection{Showing Bytecode}
After generating the bytecode necessary for EVM to run, we can display it without running it; but one has to be careful: generating the bytecode requires the actually code generation phase, which means code will be wholly evaluated and type-checked before we can evaluate the code.
\par The generated bytecode then can be safely used to deploy the contract with accompanied ABI (see \ref{abi-module}).
\subsection{Showing Disasm}
Another important feature of Cenary compiler is that we can make it show the EVM assembly code that will be generated for a Cenary source. This is especially helpful to debug smaller programs, but it's increasingly difficult to debug larger programs since potentially assembly code can grow into 6000+ lines of assembly.
\subsection{ABI Module}
\label{abi-module}
ABI stands for Application Binary Interface, which is a specification of callable functions and their input/outputs in json format. In order to make deployment painless, a good smart contract compiler should be able to generate ABI for any of its program, and Cenary can do that. With modules $Cenary.ABI$ and $Cenary.AbiBridge$, we can transform our AST to ABI and json-encode it before deployment. Just before every deployment, Cenary compiler encodes the abi for given program and substitutes a pre-decided string (@abi@ in our case) in our deployment script. This is currently a dirty way of handling deployment, but it does its job and we've already written several smart contracts this way.
\par Being able to transform AST to ABI with just one pure function and being able to collect errors is a powerful feature we use thanks to Haskell language. In fact, in the $Cenary.AbiBridge$ module, we don't even know the details of how to convert an AST to ABI, we just call the $Cenary.ABI$ module's function and that's it.

\newpage

\section{Conclusion}
This report concludes the development of Cenary as a senior project in Boğaziçi University. Development of Cenary will continue, and we can see Cenary as a viable alternative to other smart contract languages out there in the future.
\par Future plans for Cenary includes the language CenaryIR. We plan the current Cenary to be a intermediate representation (IR) language, and a new language called Cenary will be built upon CenaryIR as a high level pure functional language. This way, we continue developing Cenary and CenaryIR in parallel, with Cenary facing towards the user, and CenaryIR getting more and more low-level, and ideally, we stop the development of CenaryIR and only continue developing Cenary since the only mission of the CenaryIR will be to be an imperative bridge between EVM assembly and Cenary. For this very task, we wanted to keep Cenary's syntax very lightweight and c-like since the compiler will be the one who generates code in this language.
\newpage
\begin{thebibliography}{2}
\bibitem{hash-table-poisoning}
  Are Ethereum Contracts Vulnerable to Hash Table Poisoning Attacks?: https://hackernoon.com/are-ethereum-contracts-vulnerable-to-hash-table-poisoning-attacks-a4d9241e16c4
\end{thebibliography}

\end{document}
